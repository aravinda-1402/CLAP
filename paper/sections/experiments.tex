Experiments are driven by a YAML config (\texttt{experiments/config.yaml} or \texttt{config\_mock.yaml}). The default seed is 42; the number of base cases and which suites to run are configurable. For mock runs, no API key is required; the MockModel returns deterministic, schema-compliant JSON so the pipeline can be validated offline. For real LLM runs, set \texttt{adapter: openai} and provide the appropriate API key; outputs are cached to avoid re-calling. Each run produces an audit packet (JSON and PDF), CSV tables in \texttt{outputs/tables/}, and figures in \texttt{outputs/figures/}. The same config hash and git commit are recorded in the packet for reproducibility.
